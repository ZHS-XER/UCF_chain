# UCF Chain - 视频帧排序实验 (Ordering Experiment)

本项目实现了一个基于大型视觉语言模型的视频帧时序排序实验，旨在评估模型对视频动作连续性和时序关系的理解能力。

## 实验概述

实验使用UCF动作识别数据集，包含多种体育活动视频（Biking、Billiards、BlowingCandles、Diving、HighJump等）。从每个视频中抽取5帧图像，将其打乱顺序后要求模型预测正确的时间顺序，以此测试模型的时序推理能力。

## 核心模块详解

### 1. extract.py - 视频帧提取
**功能：** 从UCF原始视频中提取关键帧
- 按每秒1帧的频率提取帧图像
- 将帧大小调整为224x224像素
- 按类别和视频ID组织存储结构
- 帧命名采用填充前导0格式（如frame_00001.jpg）

**使用方法：**
```bash
python extract.py
```

**输出结构：**
```
data/frames/
├── Biking/
│   ├── v_Biking_g01_c01/
│   │   ├── frame_00001.jpg
│   │   ├── frame_00002.jpg
│   │   └── ...
│   └── v_Biking_g01_c02/
└── Diving/
    └── ...
```

### 2. build_ordering.py - 排序任务构建
**功能：** 生成标准化的排序测试数据集
- 从每个视频均匀采样5帧（如果视频帧数不足5则跳过）
- 随机打乱帧的顺序作为测试输入
- 计算正确排序的索引映射关系
- 按字典序对类别和视频进行排序，确保结果可重现

**核心算法：**
```python
def compute_correct_order(frames, shuffled):
    """
    计算correct_order：对于原始frames中的每一帧，
    找到它在shuffled序列中的位置索引
    """
```

**输出：** `data/ordering.json` - 包含所有排序任务的标准化数据

### 3. main_ordering.py - 模型测试与评估
**功能：** 执行排序实验并进行多维度评估

#### 核心流程：
1. **图像预处理：** 将帧编码为base64格式用于API调用
2. **结构化输出：** 要求模型按指定JSON格式返回结果
3. **多维度评估：** 计算多种准确率指标
#### 模型输出格式：
```json
{
  "frame_descriptions": ["描述frame_0的内容", "描述frame_1的内容", ...],
  "reasoning": "详细的推理过程",
  "predicted_order": [2, 0, 1, 4, 3]
}
```

#### 断点续传功能：
- 自动跳过已完成的任务，支持实验中断后继续执行
- 实时显示当前进度和累计准确率

### 4. generate_summary.py - 结果分析与统计
**功能：** 生成实验的全面统计报告

#### 统计维度：
- **总体统计：** 整体正确率、平均配对准确率、平均Kendall's tau
- **类别统计：** 按动作类别（Biking、Diving等）分别统计各项指标
- **详细记录：** 每个视频的预测顺序、正确顺序和评估结果

#### 输出格式优化：
- 使用紧凑的JSON格式，数组显示在同一行
- 提供控制台友好的统计摘要输出

## 评估机制详解

### 1. 严格匹配评估 (Exact Match)
- **标准：** 预测序列与真实序列完全一致
- **计算：** 二值判断（完全正确/错误）
- **特点：** 最严格的评估标准，但无法反映部分正确的价值

### 2. 配对准确率评估 (Pairwise Accuracy)
- **原理：** 统计所有元素对(i,j)在预测和真实排序中相对顺序的一致性
- **计算公式：** 一致对数 / 总对数
- **优势：** 能够量化部分正确的排序质量，对轻微错误更宽容

### 3. Kendall's tau系数
- **公式：** τ = (一致对数 - 不一致对数) / 总对数
- **范围：** [-1, 1]
  - 1: 完全一致
  - 0: 随机排序
  - -1: 完全颠倒
- **意义：** 提供排序相关性的标准化度量，便于不同实验间比较

### 配对评估示例
```
原始顺序: [0, 1, 2, 3, 4]
预测顺序: [0, 1, 3, 2, 4]
分析: 只有(2,3)这一对顺序颠倒了
配对准确率: 9/10 = 90%
Kendall's tau: (9-1)/10 = 0.8
```

## 实验设计细节

### 1. 数据集选择
- 使用UCF动作识别数据集
- 每个类别包含多个视频，确保多样性和代表性

### 2. 多维度评估体系
- 结合严格匹配、配对准确率和Kendall's tau三种指标
- 从不同角度全面评估模型的时序理解能力
- 提供更细致和公平的评估结果

### 3. 实验可重现性
- 对所有输入进行字典序排序
- 使用固定的采样策略和随机种子
- 生成标准化的测试数据集

### 4. 工程实用性
- 异步处理提升实验效率
- 断点续传避免重复计算
- 结构化输出便于后续分析

## 使用方法

### 完整实验流程：

1. **提取视频帧：**
   ```bash
   python extract.py
   ```

2. **构建排序任务：**
   ```bash
   python build_ordering.py
   ```

3. **执行排序实验：**
   ```bash
   python main_ordering.py
   ```

4. **生成统计报告：**
   ```bash
   python generate_summary.py
   ```

### 结果查看：
- **单个结果：** `results_ordering/视频名.json`
- **统计摘要：** `ordering_summary.json`
- **实时输出：** 控制台显示实验进度和准确率

## 输出结果结构

### 单个任务结果：
```json
{
  "video": "v_Biking_g01_c01",
  "frame_descriptions": ["第一帧描述", "第二帧描述", ...],
  "reasoning": "模型的详细推理过程",
  "predicted_order": [2, 0, 1, 4, 3],
  "shuffled_frames": ["打乱后的帧路径列表"],
  "correct_order": [1, 2, 0, 4, 3],
  "is_correct": false,
  "pairwise_metrics": {
    "concordant_pairs": 8,
    "discordant_pairs": 2,
    "total_pairs": 10,
    "pairwise_accuracy": 0.8,
    "kendall_tau": 0.6
  }
}
```

### 统计摘要结构：
```json
{
  "statistics": {
    "total": 50,
    "correct": 12,
    "accuracy": 0.24,
    "average_pairwise_accuracy": 0.75,
    "average_kendall_tau": 0.52
  },
  "category_statistics": {
    "Biking": {
      "total": 10,
      "correct": 3,
      "accuracy": 0.30,
      "average_pairwise_accuracy": 0.80,
      "average_kendall_tau": 0.60
    }
  }
}
```

## 实验意义

这个排序实验为评估大型视觉语言模型在以下方面的能力提供了标准化框架：

1. **时序推理能力：** 理解动作的自然发展顺序
2. **视觉理解深度：** 从静态图像推断动态过程
3. **逻辑连贯性：** 基于部分信息进行完整性推理
4. **鲁棒性评估：** 在有干扰信息下的表现稳定性

通过多维度的评估机制，实验结果能够为视频理解、动作识别、时序预测等领域的研究提供有价值的参考数据。
